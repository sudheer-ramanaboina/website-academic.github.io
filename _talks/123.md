## Papers

1. [MoE-LLaVA: Mixture of Experts for Large Vision-Language Models](https://arxiv.org/abs/2401.15947),arxiv 2024 , [[Code]](https://github.com/PKU-YuanGroup/MoE-LLaVA)

***
## LS Table

| Sl.No | Paper title| Year | Frame work | dataset |
| ----- | ---------- | ---- | ---------- | ------- |
| 01 | MoE-LLaVA: Mixture of Experts for Large Vision-Language Models | 2024 | Pytorch | LLaVA 1.5-558k,MIMIC-IT,LRV,SViT,LVIS |
| 02 | LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation, Generation and Editing | 2023 | Pytorch | NA |
| 03 | Video-LLaVA: Learning United Visual Representation by Alignment Before Projection | 2023 | Pytorch | MSVD-QA,MSRVTT-QA,TGIF-QA,ActivityNet-QA |


